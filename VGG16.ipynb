{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68b30f7347a04cd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data for the heatmap\n",
    "data = {\n",
    "    'Model': [\n",
    "        'VGG16 Basic Integration Model (3)', 'VGG16 Basic Integration Data Model (5)', 'VGG16 Augmented Data Model (3)',\n",
    "        'VGG16 Augmented Data Model (5)', 'VGG16 Augmented Data Model Vertical Flips (3)', 'VGG16 Augmented Data Model Vertical Flips (5)','VGG16 Fine Tuning Model (5)',\n",
    "        'Normalization Focus Model (5)', 'Multi Model (5)'\n",
    "    ],\n",
    "    'Accuracy': [0.61, 0.62, 0.61, 0.63, 0.61, 0.65, 0.62, 0.62, 0.62],\n",
    "    'Precision': [0.57, 0.59, 0.66, 0.58, 0.59, 0.65, 0.62, 0.59, 0.58],\n",
    "    'Recall': [0.84, 0.79, 0.46, 0.83, 0.75, 0.64, 0.60, 0.76, 0.84],\n",
    "    'F1-Score': [0.68, 0.68, 0.54, 0.69, 0.65, 0.65, 0.62, 0.66, 0.70]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set the model as the index\n",
    "df.set_index('Model', inplace=True)\n",
    "\n",
    "# Plotting the heatmap with a standard color map (viridis)\n",
    "plt.figure(figsize=(10, 8))\n",
    "heatmap = sns.heatmap(df, annot=True, fmt=\".2f\", cmap='Blues')\n",
    "plt.title('Heatmap of Model Performances')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('C:/Desktop/Img/heatmap.png')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f554c6908cfed8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data for the heatmap\n",
    "data = {\n",
    "    'Model': ['BERT and VGG16', 'BERT and ResNet50'],\n",
    "    'Accuracy': [0.62, 0.53],\n",
    "    'Precision': [0.59, 0.65],\n",
    "    'Recall': [0.77, 0.13],\n",
    "    'F1-score': [0.66, 0.21]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_new = pd.DataFrame(data)\n",
    "\n",
    "# Set the model as the index\n",
    "df_new.set_index('Model', inplace=True)\n",
    "\n",
    "# Plotting the heatmap with seaborn using the blue color map\n",
    "plt.figure(figsize=(8, 3)) \n",
    "heatmap_new = sns.heatmap(df_new, annot=True, fmt=\".2f\", cmap='Blues')  # Using 'Blues' color map\n",
    "\n",
    "# Adjust layout to make room for model names\n",
    "plt.tight_layout()\n",
    "\n",
    "# Title of the heatmap\n",
    "plt.title('Heatmap of Model Metrics')\n",
    "\n",
    "plt.savefig('C:/Desktop/Img/heatmap_blue.png')  \n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "935180c0e991b87b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Data from the provided heatmap image\n",
    "data = {\n",
    "    'Model': [\n",
    "        'LR',\n",
    "        'SVM',\n",
    "        'BERT-Base-Uncased',\n",
    "        'DistilBERT',\n",
    "        'LR and Bert Embeddings',\n",
    "        'SVM and Bert Embeddings'\n",
    "    ],\n",
    "    'Accuracy': [0.63, 0.63, 0.61, 0.65, 0.6, 0.6],\n",
    "    'Precision': [0.55, 0.57, 0.57, 0.62, 0.58, 0.58],\n",
    "    'Recall': [0.7, 0.65, 0.91, 0.78, 0.7, 0.71],\n",
    "    'F1-Score': [0.6, 0.63, 0.69, 0.69, 0.64, 0.64]\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df_models = pd.DataFrame(data)\n",
    "\n",
    "# Set the 'Model' column as the index\n",
    "df_models.set_index('Model', inplace=True)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_models, annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.title('Performance Metrics of Text Classification Models')\n",
    "plt.tight_layout() \n",
    "\n",
    "plt.savefig('C:/Desktop/Img/heatmap.png')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9683ac9fc0a44b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Data from the provided heatmap image\n",
    "data = {\n",
    "    'Model': [\n",
    "        'LR',\n",
    "        'SVM',\n",
    "        'BERT-Base-Uncased',\n",
    "        'DistilBERT',\n",
    "        'LR and Bert Embeddings',\n",
    "        'SVM and Bert Embeddings'\n",
    "    ],\n",
    "    'Accuracy': [0.63, 0.63, 0.61, 0.65, 0.6, 0.6],\n",
    "    'Precision': [0.55, 0.57, 0.57, 0.62, 0.58, 0.58],\n",
    "    'Recall': [0.7, 0.65, 0.91, 0.78, 0.7, 0.71],\n",
    "    'F1-Score': [0.6, 0.63, 0.69, 0.69, 0.64, 0.64]\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame and set the 'Model' column as the index\n",
    "df_models = pd.DataFrame(data).set_index('Model')\n",
    "\n",
    "# Plot the heatmap with the specified color map\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_models, annot=True, fmt=\".2f\", cmap='Blues')  # Using 'Blues' color map\n",
    "plt.title('Performance Metrics of Text Classification Models')\n",
    "plt.tight_layout()  \n",
    "\n",
    "# Save the heatmap to a file\n",
    "plt.savefig('C:/Desktop/Img/heatmap2.png') \n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f8f6d2f345f81d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "from torch.nn.functional import sigmoid\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5532469acb481aae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model1:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "508df40cef89012f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab215cd3c70136f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ee4d78f0fedee8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e4776be4b5f184c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# Count occurrences of labels '0' and '1' for training data\n",
    "train_label_counts = train_df['label'].value_counts()\n",
    "\n",
    "# Count occurrences of labels '0' and '1' for validation data\n",
    "val_label_counts = val_df['label'].value_counts()\n",
    "\n",
    "# Define labels\n",
    "labels = ['Not Misogynistic', 'Misogynistic']\n",
    "\n",
    "# Plotting for training data\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # Subplot 1 for training data\n",
    "plt.bar(labels, train_label_counts.values, color=['green', 'red'])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.title('Training Data')\n",
    "\n",
    "# Plotting for validation data\n",
    "plt.subplot(1, 2, 2)  # Subplot 2 for validation data\n",
    "plt.bar(labels, val_label_counts.values, color=['green', 'red'])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Instances')\n",
    "plt.title('Validation Data')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'C:\\Desktop\\Img\\datset.png')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c43e362531c3a060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfb9392a96c075ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75ab7cc15cc544a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e621ae5253aeb455"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index : index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da61dd37f92062f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_dataset = generator_to_dataset(X_train_text, train_image_gen, batch_size)\n",
    "# val_dataset = generator_to_dataset(X_val_text, val_image_gen, batch_size)\n",
    "# train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "# val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2731257b1e6cc40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "606dbbe76891b2b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history1 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=5\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ccd10512e9c49f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values  \n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537c0ff34b5b6b3d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fa742ebab1e4fe7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "# Calculate the number of batches/steps\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63765c2b4f1cd0a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model two:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaffc2e1b9c38585"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 32\n",
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# train_dataset = generator_to_dataset(X_train_text, train_image_gen, batch_size)\n",
    "# val_dataset = generator_to_dataset(X_val_text, val_image_gen, batch_size)\n",
    "# train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "# val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=3\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b9fed6db5c903c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "# Calculate the number of batches/steps\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac6330e21fdbacb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a3e47966b104733"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# train_dataset = generator_to_dataset(X_train_text, train_image_gen, batch_size)\n",
    "# val_dataset = generator_to_dataset(X_val_text, val_image_gen, batch_size)\n",
    "# train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "# val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history3 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=3\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5530d13bfa495d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values \n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8affb69153d0984"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4790c857d748a29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# train_dataset = generator_to_dataset(X_train_text, train_image_gen, batch_size)\n",
    "# val_dataset = generator_to_dataset(X_val_text, val_image_gen, batch_size)\n",
    "# train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "# val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history8 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=6\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f100a6a561041b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values \n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b7eac593145720"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea41d20a43aa61f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# ImageDataGenerator setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Creating generators\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Function to convert generator to dataset\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "# Model architecture with increased complexity and VGG16 fine-tuning\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(512, activation='relu')(text_input)\n",
    "text_features = Dropout(0.5)(text_features)\n",
    "text_features = Dense(256, activation='relu')(text_features)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:-4]:  # Freeze all but the last 4 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(512, activation='relu')(x)\n",
    "image_features = Dropout(0.5)(image_features)\n",
    "image_features = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Correct parameter name\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue with the learning rate scheduler and model training as before\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "history4 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=3,\n",
    "    callbacks=[reduce_lr]  # Adding the ReduceLROnPlateau callback\n",
    ")\n",
    "   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "423b05ed7a9ecdf9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values \n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "# Calculate the number of batches/steps\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f57792cb0f4b8873"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e54ba9612ef75c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "\n",
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# ImageDataGenerator setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Creating generators\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Function to convert generator to dataset\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "# Model architecture with increased complexity and VGG16 fine-tuning\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(512, activation='relu')(text_input)\n",
    "text_features = Dropout(0.5)(text_features)\n",
    "text_features = Dense(256, activation='relu')(text_features)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers[:-4]:  # Freeze all but the last 4 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(512, activation='relu')(x)\n",
    "image_features = Dropout(0.5)(image_features)\n",
    "image_features = Dense(256, activation='relu')(image_features)\n",
    "\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Correct parameter name\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue with the learning rate scheduler and model training as before\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "history6 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=[reduce_lr]  # Adding the ReduceLROnPlateau callback\n",
    ")\n",
    "   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39f936bea35eacfc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "test_images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n",
    "\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "# Extract BERT embeddings and labels for the test set\n",
    "X_test_text = test_df.iloc[:, :767].values \n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# ImageDataGenerator for normalization, same as for training and validation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important for evaluation to maintain order\n",
    ")\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "results = model.evaluate(test_dataset, steps=len(test_df) // test_image_gen.batch_size)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "test_dataset = generator_to_dataset(X_test_text, test_image_gen)\n",
    "\n",
    "# Calculate the number of batches/steps\n",
    "num_steps = math.ceil(len(test_df) / test_image_gen.batch_size)\n",
    "\n",
    "# Initialize lists to store predictions and actual labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Iterate through the test dataset for a finite number of steps\n",
    "for step, ((text_batch, image_batch), labels_batch) in enumerate(test_dataset.take(num_steps)):\n",
    "    # The model expects a list of inputs: [text_input, image_input]\n",
    "    batch_predictions = model.predict([text_batch, image_batch])\n",
    "    # Store predictions and labels\n",
    "    all_predictions.extend(batch_predictions.squeeze())\n",
    "    all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays for metric calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "binary_predictions = (all_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(all_labels, binary_predictions)\n",
    "precision = precision_score(all_labels, binary_predictions)\n",
    "recall = recall_score(all_labels, binary_predictions)\n",
    "f1 = f1_score(all_labels, binary_predictions)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b9636c2eecdf1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 9 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4667e87064f10f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 32\n",
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# train_dataset = generator_to_dataset(X_train_text, train_image_gen, batch_size)\n",
    "# val_dataset = generator_to_dataset(X_val_text, val_image_gen, batch_size)\n",
    "# train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "# val_dataset = val_dataset.batch(batch_size, drop_remainder=True)\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history9 = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=3\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6605c4ce857968d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model 10 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f115f4e719e90e40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_csv_path = r'C:\\Desktop\\train_embeddings_with_text.csv'\n",
    "val_csv_path = r'C:\\Desktop\\val_embeddings_with_text.csv'\n",
    "images_folder_path = r'C:\\Desktop\\training\\TRAINING'\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "\n",
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "# Step 3: Set up the ImageDataGenerator for normalization and data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "batch_size = 32\n",
    "\n",
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen_augmented = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "def generator_to_dataset(text_data, image_data_generator):\n",
    "    def generator():\n",
    "        # Start by creating an index to keep track of the batch\n",
    "        index = 0\n",
    "        for batch in image_data_generator:\n",
    "            image_batch, labels_batch = batch\n",
    "            # Compute the size of the batch\n",
    "            batch_size = image_batch.shape[0]\n",
    "            # Slice the text data to get the matching embeddings\n",
    "            text_batch = text_data[index: index + batch_size]\n",
    "            index += batch_size\n",
    "            yield (text_batch, image_batch), labels_batch\n",
    "            # Reset the index if we've gone through the entire data\n",
    "            if index + batch_size > len(text_data):\n",
    "                index = 0\n",
    "\n",
    "    # Determine output types and shapes for the dataset\n",
    "    output_shapes = ((tf.TensorShape([None, 767]), tf.TensorShape([None, 224, 224, 3])), tf.TensorShape([None]))\n",
    "    output_types = ((tf.float32, tf.float32), tf.float32)\n",
    "\n",
    "    # Create a dataset from the Python generator\n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_types=output_types, output_shapes=output_shapes)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = generator_to_dataset(X_train_text, train_image_gen_augmented)\n",
    "val_dataset = generator_to_dataset(X_val_text, val_image_gen)\n",
    "\n",
    "text_input = Input(shape=(767,), name='text_input')\n",
    "text_features = Dense(256, activation='relu')(text_input)\n",
    "text_features = Dropout(0.7)(text_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Image input: using VGG16 as the base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = base_model(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "image_features = Dense(256, activation='relu')(x)\n",
    "image_features = Dropout(0.7)(image_features)  # Add dropout with rate 0.7\n",
    "\n",
    "# Combine the outputs of the two branches\n",
    "combined_features = concatenate([text_features, image_features])\n",
    "\n",
    "# Add a classification layer\n",
    "predictions = Dense(1, activation='sigmoid')(combined_features)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=len(train_df) // batch_size,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=len(val_df) // batch_size,\n",
    "    epochs=5\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "242544c306d7da4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from keras.applications import VGG16\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a62723505c18c19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['label'].astype('float32')\n",
    "val_df['label'] = val_df['label'].astype('float32')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7205974e57db22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbec8d39e04b8b7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2: Extract BERT embeddings and labels\n",
    "X_train_text = train_df.iloc[:, :767].values\n",
    "X_val_text = val_df.iloc[:, :767].values\n",
    "y_train = train_df['label'].values\n",
    "y_val = val_df['label'].values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15aa53bed86525b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 3: Set up the ImageDataGenerator for normalization\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f685f127eedcfe3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 4: Create generators for the images and labels using flow_from_dataframe\n",
    "train_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',\n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70e330c847cfa601"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "input_image = layers.Input(shape=(224, 224, 3))\n",
    "vgg_model = VGG16(input_tensor=input_image, weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = vgg_model.output\n",
    "x = layers.Flatten(input_shape=vgg_model.output_shape[1:])(x)\n",
    "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "image_model = Model(vgg_model.input, x)\n",
    "\n",
    "image_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "image_model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = image_model.fit(\n",
    "    train_image_gen,\n",
    "    validation_data=val_image_gen,\n",
    "    epochs=5\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f15db1340c6b49bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "image_model.save(\"my_vgg_model.h5\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29e0486424ce42ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Define the input shape for the text embeddings\n",
    "#text_input = Input(shape=(X_train_text.shape[1],))\n",
    "text_input = Input(shape=(767,), name='text_input') \n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "x = Dense(256, activation='relu')(text_input)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  \n",
    "\n",
    "# Compile the model\n",
    "text_model = Model(inputs=text_input, outputs=output)\n",
    "text_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model = text_model.fit(X_train_text, y_train, validation_data=(X_val_text, y_val), epochs=5, batch_size=batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = text_model.evaluate(X_val_text, y_val)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "# Save the model\n",
    "text_model.save('./TextModel/text_model.h5')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "224985d229ad6c77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained models\n",
    "image_model = load_model(\"my_vgg_model.h5\")\n",
    "text_model = load_model(\"./TextModel/text_model.h5\")\n",
    "\n",
    "for layer in image_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in text_model.layers:\n",
    "    layer.trainable = False\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b79b9618e0ec1b69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Define input layers for image and text data\n",
    "input_image = Input(shape=(224, 224, 3), name='image_input')\n",
    "input_text = Input(shape=(767,), name='text_input')  \n",
    "\n",
    "\n",
    "# Get the output tensors of the image and text models\n",
    "image_output = image_model(input_image)\n",
    "text_output = text_model(input_text)\n",
    "\n",
    "# Concatenate the outputs of both models\n",
    "combined_output = Concatenate()([image_output, text_output])\n",
    "\n",
    "\n",
    "# Add a final output layer for classification\n",
    "final_output = Dense(1, activation='sigmoid')(combined_output)\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[input_image, input_text], outputs=final_output)\n",
    "\n",
    "# Compile the combined model\n",
    "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the combined model\n",
    "combined_model.summary()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b5283df6d3d5889"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def combined_generator(image_gen, text_data, labels):\n",
    "    while True:\n",
    "        image_batch, label_batch = next(image_gen)\n",
    "        text_batch = text_data[:len(image_batch)]  # Fetch corresponding text data\n",
    "        yield {'image_input': image_batch, 'text_input': text_batch}, label_batch\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52660b423db9c141"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_gen = combined_generator(train_image_gen, X_train_text, y_train)\n",
    "val_combined_gen = combined_generator(val_image_gen, X_val_text, y_val)\n",
    "\n",
    "# Calculate steps per epoch for training and validation\n",
    "steps_per_epoch = len(train_df) // batch_size\n",
    "validation_steps = len(val_df) // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = combined_model.fit(\n",
    "    combined_gen, \n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_combined_gen, \n",
    "    validation_steps=validation_steps,\n",
    "    epochs=5\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e8411047811a5c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_folder_path = r'C:\\Desktop\\test\\test'\n",
    "test_csv_path = r'C:\\Desktop\\test_embeddings_with_text.csv'\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c93517daf41349ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Convert the 'label' column to string if it's intended for use with Keras' flow_from_dataframe\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "X_test_text = test_df.iloc[:, :767].values  \n",
    "y_test = test_df['label'].values.astype('float32') \n",
    "\n",
    "# Initialize the ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a generator for the test images\n",
    "test_image_gen = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=images_folder_path,\n",
    "    x_col='file_name',  \n",
    "    y_col='label',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  \n",
    "    class_mode='binary',  \n",
    "    shuffle=False  \n",
    ")\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the pre-trained models\n",
    "image_model = load_model(\"my_vgg_model.h5\")\n",
    "text_model = load_model(\"text_model.h5\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc29abbab59cef39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# Reset the test_image_gen before iterating\n",
    "test_image_gen.reset()\n",
    "\n",
    "for i in range(0, len(test_df), test_image_gen.batch_size):\n",
    "    images_batch = next(test_image_gen)[0]  # Extract images\n",
    "    \n",
    "    # Calculate the end index for the current batch\n",
    "    end = min(i + test_image_gen.batch_size, len(X_test_text))\n",
    "    text_batch = X_test_text[i:end]\n",
    "    \n",
    " \n",
    "    if len(text_batch) != len(images_batch):\n",
    "        print(f\"Warning: Mismatched batch sizes. Images: {len(images_batch)}, Text: {len(text_batch)}\")\n",
    "        \n",
    "    batch_predictions = combined_model.predict({'image_input': images_batch, 'text_input': text_batch})\n",
    "    all_predictions.extend(batch_predictions)\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df492eda1c378fdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "binary_predictions = (all_predictions > 0.5).astype(int)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9be0397beb153d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "precision = precision_score(y_test, binary_predictions)\n",
    "recall = recall_score(y_test, binary_predictions)\n",
    "f1 = f1_score(y_test, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c5db759c345309d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, binary_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(r'C:\\Desktop\\Img\\ConfusionMatrix.png')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f125bb979e6cb4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, all_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig(r'C:\\Desktop\\Img\\Receiver-Operating-Characteristic-Curve.png')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5f5b77b9676bb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.savefig(r'C:\\Desktop\\Img\\Precision-Recall-Curve.png')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3e930072a1da32b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "816a13a7e5ce0af1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
